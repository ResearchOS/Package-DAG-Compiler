{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Package-DAG-Compiler","text":"<p>The Directional Acyclic Graph (DAG) is a data structure (a type of Graph) that at its most fundamental level consists of nodes and directed (Directional) edges, and does not contain any loops (Acyclic). Typically, nodes are objects, and directed edges are the directional relationships between them, such as <code>gas -&gt; car</code> indicating that the car depends on gas. It is the same in this package. Typically, edges are notated using some variant of <code>source -&gt; target</code> (equivalently, <code>(source, target)</code>), which can be read in one of two ways:</p> <ol> <li>The target depends on the source.</li> <li>The source feeds in to the target.</li> </ol> <p>The second, more source-centric interpretation guides the design philosophy of this package. In the context of a workflow orchestration tool, where data flows from a dataset to a final output, I think this makes more sense. In the DAG, nodes are Runnable functions and the edges are the Variables' data flowing between them, the edges look more like <code>Runnable -&gt; Variable</code> which can be read as \"data from this Runnable node flows into this output Variable\". Similarly, <code>Variable -&gt; Runnable</code> indicates that data flows from a Variable and is an input to a Runnable.</p> <p>In this package, edges carry no meaning or metadata, they simply define directional connectivity. All of the metadata is contained in the node properties.</p> <p>At a high level, there are two types of nodes: Runnables, and Variables. Runnables represent things that you run, generally a function that you can call or a script you can run. Categories of Runnables include Process, Stats, and Plot. More on those later. The other node type is Variables, which as you would expect help direct the flow of data. Runnable nodes can only directly connect to Variables, they cannot connect to each other directly. However, Variable nodes can connect to either a Runnable or another Variable. The edges between nodes, whether they be Runnable -&gt; Variable, Variable -&gt; Runnable, or Variable - Variable, represent the flow of data between steps in a data processing pipeline. There can only be one connection between an output variable node and an input variable node without triggering a split in the DAG. A split is exactly what it sounds like. An exact copy of the subgraph of nodes descended from the current  Runnable node is created, and attached to that same Runnable node.</p> <p>Further Reading: 1. Recommended package directory structure     - Can use a template to generate the TOML files and directory structure 3. How to use this package     - Example project     - Templates     - Documentation per function     - Output is NetworkX graph</p>"},{"location":"dag_structure/","title":"DAG Structure","text":"<p>Todo</p> <ol> <li>Understand the types of DAG's that this compiler may generate. At the moment, it only puts out furcated (split) graphs. </li> <li>What does a split represent, why do I want it, and how do I trigger it?</li> <li></li> <li> <p>How the DAG is structured</p> <ul> <li>Node naming conventions, and how it relates to TOML</li> <li>Node metadata. Which metadata changes the hash?  </li> </ul> </li> <li> <p>Polyfurcations. What are they, when do they occur, why are they good, and what are the implementation details?</p> </li> </ol>"},{"location":"templates/","title":"Template Structure","text":"<p>Todo</p> <p>Templates for new projects can be created using <code>ros create $package_name</code>. This section defines the structure of the template. What is the directory structure, which files are included, what information needs to be entered in order to share the package? How to integrate with others' packages?</p>"},{"location":"terms/","title":"Glossary","text":""},{"location":"terms/#a-note-on-notation","title":"A note on notation","text":"<p>Throughout the glossary and the docs, you may see notation for file and folder paths that include dollar signs <code>$</code>. Whatever comes after this symbol is intended to be a dynamic variable, e.g. <code>$project_folder</code> will be replaced with the actual folder path for your project.</p>"},{"location":"terms/#dag","title":"DAG","text":"<p>The output of this package is a Directional Acyclic Graph (DAG) consisting of nodes and edges as NetworkX MultiDiGraph object. Nodes can be Runnables or Variables, and edges are the connections between nodes. </p>"},{"location":"terms/#indextoml","title":"index.toml","text":"<p>Recommended to be located at <code>$project_folder/src/$project_name/index.toml</code>. This file contains all of the file paths to all of the files that comprise this package. For maximum flexibility, the only requirement as to the structure of this file is that it consist only of dictionaries (with any degree of nesting for organizational purposes), where each key is a user-defined string, and the values are either a subdictionary, or a file path. No other strings, no numbers, or lists are allowed outside of dictionaries. Relative file paths are preferred for portability. They are relative to the <code>$project_folder/src/$project_name</code> directory, as that is the root directory when the package is installed. Absolute file paths should be used only when needed to access files outside of the project folder.</p>"},{"location":"terms/#pyprojecttoml","title":"pyproject.toml","text":"<p>Recommended to be located at the root of your project folder, <code>pyproject.toml</code> is a type of text file that is Python's default way of providing the metadata needed to share Python packages. This is the only Python-standard .toml file, the rest are custom-defined in this package for the purposes of compiling a DAG from a TOML-based modular package format.</p>"},{"location":"terms/#variable","title":"Variable","text":"<p>A Variable node in the DAG is an input Variable if its successor is a Runnable, and an output Variable if its predecessor is a Runnable. Input Variables can be any of several types: hard-coded, loading a file, specifying a data object's name or file path, or even unspecified. Output variables do not have these delineations - they are all simply \"outputs\".</p>"},{"location":"terms/#runnable","title":"Runnable","text":"<p>\"Runnable\" is an umbrella term for any node type that is not a Variable, and executes code. The default Runnable types are Process, Plot, PlotComponent, and Summary (in development). There are different types of Runnables because they each require different attributes to function, though some attributes are mandatory and shared between all Runnable types.</p>"},{"location":"terms/#runnable-process","title":"Runnable: Process","text":"<p>The most common type of Runnable. Takes in data, processes it by executing the associated code, and outputs data.</p>"},{"location":"terms/#runnable-plot","title":"Runnable: Plot","text":"<p>Runnable that visualizes data. Takes in data and metadata about the Plot, Axes, and PlotComponent to construct and save the plot. NOTE: Plots themselves do not have code associated with them. However, PlotComponents do.</p>"},{"location":"terms/#runnable-plotcomponent","title":"Runnable: PlotComponent","text":"<p>Todo</p> <p>Used by Plot-type Runnables to define a single layer of the plot. Executes the plotting functions, while Plot Runnables themselves do not.</p>"},{"location":"terms/#runnable-summary","title":"Runnable: Summary","text":"<p>Todo</p> <p>Responsible for summarizing the data so it can be entered into statistical analysis.</p>"},{"location":"toml_files/","title":"TOML Configuration Files","text":"<p>TOML (Tom's Obvious Minimal Language) is a configuration file syntax that defines a format for human and machine-readable structured plain text. I like it a lot because it's just as full featured as JSON and YAML, has multiple ways to represent the same dictionaries, unlike JSON and YAML (which I find helpful), and due to negligible indentation, TOML is a very robust and easy to work with language. Its primary downside is that it has not been around for as long as YAML or JSON, and so not every language has an existing TOML parser, and not all TOML parsers are created equal (some may not handle the more advanced features in TOML like arrays of tables).</p>"},{"location":"toml_files/#pyprojecttoml","title":"pyproject.toml","text":"<p>Python relies on pyproject.toml files for publishing packages. The default file structure is: <pre><code>[build-system]\nrequires = ['hatchling']\nbuild-backend = 'hatchling.build'\n\n[project]\nname = \"package_name\"\nversion = '0.1.0'\ndescription = 'Package description'\nauthors = [{name = \"Author Name\", email =\"author@email.com\"}]\ndependencies = []\n\n[tool.hatch.build.targets.wheel]\npackages = [\"src/package_name\"]\n\n[tool.package-dag-compiler]\nindex = \"index.toml\" # Path to the package's index.toml file\n</code></pre></p>"},{"location":"toml_files/#indextoml","title":"index.toml","text":"<p>This file points to all of the other files in the package. It can be any format, but every value must be a file path. At its simplest, it could contain just one file path: <pre><code>package_file = \"path/to/package_file.toml\"\n</code></pre> In larger packages with more files, more organization becomes useful. For example, categorizing paths by type: <pre><code>processes = [\n    \"path/to/process1.toml\",\n    \"path/to/process2.toml\"\n]\nplots = [\n    \"path/to/plots1.toml\"\n]\n</code></pre></p>"},{"location":"toml_files/#special-keys","title":"Special keys","text":"<ul> <li>bridges: The files that help connect the current package to others. <pre><code>runnables = [\n    \"path/to/runnables1.toml\",\n    \"path/to/runnables2.toml\"\n]\nbridges = \"path/to/bridges.toml\"\n</code></pre></li> </ul>"},{"location":"toml_files/#runnablestoml","title":"runnables.toml","text":"<p>The main contents of a package reside in its 1+ runnables' .toml files, of which there are multiple types. Every type of runnable needs at minimum the following attributes: <code>type</code>, <code>exec</code>, and <code>inputs</code>.</p> <p>Example runnable format: <pre><code>[runnable_name]\ntype = \"runnable_type\"\nexec = \"path/to/file.ext:func_name\"\ninputs.input1 = \"runnable1.variable1\"\n</code></pre></p>"},{"location":"toml_files/#process","title":"Process","text":"<p>Process type runnables are the most frequent runnable type. They process and transform data, and are the only type that has output variables. Inputs are identified by name, similar to keyword arguments available in most languages. As there are no named outputs, output variables are specified in a list in the same order that they are output.</p> <pre><code>[runnable_name]\ntype = \"process\"\nexec = \"path/to/file.ext:func_name\"\ninputs.input1 = \"runnable1.variable1\"\noutputs = [\n    \"output1\",\n    \"output2\"\n]\n</code></pre>"},{"location":"toml_files/#plot","title":"Plot","text":"<p>Plot type runnables are exactly what they sound like - they plot and visualize data.</p> <pre><code>[runnable_name]\ntype = \"plot\"\nexec = \"path/to/file.ext:func_name\"\ninputs.input1 = \"runnable1.variable1\"\n</code></pre>"},{"location":"toml_files/#summary","title":"Summary","text":"<p>Summary type runnables summarize the data.</p> <pre><code>[runnable_name]\ntype = \"summary\"\nexec = \"path/to/file.ext:func_name\"\ninputs.input1 = \"runnable1.variable1\"\n</code></pre>"},{"location":"toml_files/#bridgestoml","title":"bridges.toml","text":"<p>Bridges are the mechanism by which independently developed packages are connected together. The bridge name is just an identifier (unique within each package). Sources are the origin of the variable being bridged, and targets are where the variable is being directed to. Typically, there would either be just one source and multiple targets, or one target and multiple sources.</p> <p>Most projects just need one of these bridges files, althouh multiple bridges files are supported. If you find yourself with many bridges, consider splitting the package up into smaller packages.</p> <p>Here is a basic example bridges.toml file: <pre><code>[bridge_name]\nsources = [\n    \"package1.runnable1.output1\"\n]\ntargets = [\n    \"package2.runnable1.input1\"\n]\n</code></pre></p> <p>Note that each entry contains the package name, which is not included in the package's runnables.toml files because the referenced runnables are assumed to be located within the same package. When bridging, the package name must be specified explicitly to resolve potential naming conflicts between packages.</p>"},{"location":"toml_files/#one-source-multiple-targets","title":"One source, multiple targets","text":"<p>In this case, one output variable is being used as an input to multiple runnables. This is a common practice, as there are often computed variables that need to be used by multiple functions further along the pipeline.</p>"},{"location":"toml_files/#one-target-multiple-sources","title":"One target, multiple sources","text":"<p>In this case, one input variable is receiving data from multiple sources, triggering a polyfurcation of the DAG, with one branch per input variable. Most commonly this would happen with Plot and Summary runnables, to reuse the same runnable to plot or summarize multiple variables. </p> <p>In the below example, two variables are both being connected to the input variable for a Summary runnable. <pre><code>[summaries]\nsources = [\n    \"package1.runnable1.variable1\",\n    \"package1.runnable2.variable1\"\n]\ntargets = [\n    \"package2.summary1.data\"\n]\n</code></pre></p>"},{"location":"toml_files/#multiple-targets-multiple-sources","title":"Multiple targets, multiple sources","text":"<p>Todo</p> <p>Currently unsupported and will raise an error, though in the future I aim to support this. It will be treated as though it were a series of N bridges with one target and multiple sources, where N is the number of targets. Therefore, each source will be applied to each target</p>"},{"location":"Packaging/installing_packages/","title":"Installing Packages","text":"<p>You've found a package you want to use, and now you want to install it. First, you need to put that package in your pyproject.toml file. Depending on where the package is being installed from, there are a few ways to do this using Python's default syntax. For more information than is provided here, check out the linked documentation in the sections below.</p>"},{"location":"Packaging/installing_packages/#installing-from-pypi","title":"Installing from PyPI","text":"<p>Packages installed from PyPI can be specified with their package name, and optionally version restrctions. See Python docs for details.  <pre><code>[project]\ndependencies = [\n    \"numpy\",\n    \"pandas\"\n]\n</code></pre></p>"},{"location":"Packaging/installing_packages/#installing-from-github","title":"Installing from GitHub","text":"<p>From the Hatch documentation, packages can also be installed directly from GitHub repositories. <pre><code>[project]\ndependencies = [\n    \"Package-DAG-Compiler @ git+https://github.com/ResearchOS/Package-DAG-Compiler\"\n]\n</code></pre></p>"},{"location":"Packaging/installing_packages/#installing-from-a-local-directory","title":"Installing from a local directory","text":"<p>Similarly, dependency packages can be installed from a local directory as well by specifying paths to either the package folder, a wheel (.whl), or source archive (.tar.gz). <pre><code>[project]\ndependencies = [\n    \"Package-DAG-Compiler @ file:///path/to/dependent/package/Package-DAG-Compiler\" # Package folder path\n]\n</code></pre></p>"},{"location":"Packaging/installing_packages/#installing-from-the-internet-other-than-version-control","title":"Installing from the Internet (other than version control)","text":"<p>Finally, packages can also be downloaded from any location on the Internet by specifying the package name and the link to the wheel or source archive. For example: <pre><code>[project]\ndependencies = [\n    \"pytorch @ https://download.pytorch.org/whl/cu102/torch-1.10.0%2Bcu102-cp39-cp39-linux_x86_64.whl\"\n]\n</code></pre></p>"},{"location":"Packaging/publishing_packages/","title":"Publishing Packages","text":"<p>You've created a set of TOML files, you've compiled them to a DAG, maybe you've even leveraged pre-existing packages by bridging your package with theirs, and you're ready to share your package with the world. </p>"},{"location":"Packaging/publishing_packages/#formatting","title":"Formatting","text":"<p>The packaging format described here is inteded to be flexible enough to work with projects of all sizes using the provided tools.</p> <p>Todo</p> <p>Command line tools will be provided to generate the folder structure below, including auto-populating the minimum required contents of pyproject.toml files.</p>"},{"location":"Packaging/publishing_packages/#package-folder-structure","title":"Package Folder Structure","text":"<p>Verify that your package follows the expected folder structure.</p> <pre><code>root/\n\u251c\u2500\u2500 .venv/ # created by the user with python -m venv .venv\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 $project_name/\n\u2502   \u2502   \u251c\u2500\u2500 index.toml # Package metadata\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 test_main.py\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 index.md\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 CONTRIBUTING.md\n</code></pre> <p>Use the provided tools to check that your package matches the required format.</p> <p>Todo</p> <p>A command line tool will ensure that the above folder structure is adhered to, including a <code>docs</code> and <code>tests</code> folder.</p> <p>Once your package is in the proper format and fully functioning, there are multiple ways to share your package with the world.</p>"},{"location":"Packaging/publishing_packages/#1-pypi","title":"1. PyPI","text":"<p>The Python Packaging Authority maintains the Python Packaging Index (PyPI), which is where the majority of Python packages reside. Packages in PyPI can be easily installed using <code>pip install</code>.</p>"},{"location":"Packaging/publishing_packages/#2-github-or-other-online-version-control","title":"2. GitHub (or Other Online Version Control)","text":"<p>If your package is publicly visible and hosted in an online version control platform such as GitHub or another service, you can simply leave it there! Others can pip install directly from your GitHub repository. It's always a good idea to test from another computer that your package can be successfully installed and run.</p> <p>Todo</p>"},{"location":"dev_blog/2024-10-02/","title":"October 4, 2024","text":""},{"location":"dev_blog/2024-10-02/#high-level-dag-compilation-design","title":"High-level DAG compilation design","text":"<p>To compile a DAG representing a data processing pipeline from a set of configuration files, we need to perform three steps at the highest level (at least I think it's the highest level):</p> <ol> <li> <p>Read the configuration files</p> </li> <li> <p>Clean &amp; validate the configuration files' data</p> </li> <li> <p>Construct the DAG from that data</p> </li> </ol> <p>Here's a figure of the workflow. The config file paths are read, their data returned as dicts. After validation and cleaning, the data is returned as instances of custom classes. Finally, these classes are inputs to constructing the DAG. </p> <p>Note that this seems to only be the workflow for just one package's configuration files. But an important part of this whole process is managing dependencies of other projects. For that, we need a mechanism to list and install dependencies. The pyproject.toml file is Python's modern mechanism to do exactly that. It replaces older mechanisms using setuptools.</p> <p>The problem this package needs to solve is that while the pyproject.toml file is readily available to the person developing the package, it is not typically installed along with the package when someone else <code>pip install</code>'s it. How can I resolve this?</p>"},{"location":"dev_blog/2024-10-02/#option-1-include-the-pyprojecttoml-file-in-the-distributed-package","title":"Option 1: Include the pyproject.toml file in the distributed package.","text":"<p>To include the pyproject.toml file in the distributed package, modify the pyproject.toml file to contain the following: <pre><code>[tool.hatch.build]\ninclude = [\n    \"pyproject.toml\",\n    \"src/package_dag_compiler/**\"\n]\n</code></pre> The idea is that I could loop through each subfolder in the virtual environment folder, checking for and reading each folder's pyproject.toml files to find all of the dependencies for a specific package. But I think Python and package versioning presents a problem, unless I want to loop through all of the folders.</p>"},{"location":"dev_blog/2024-10-02/#side-detour-learning-about-virtual-environment-folder-structure","title":"Side detour: Learning about virtual environment folder structure","text":"<p>Using Python's venv module, the (abbreviated) folder structure is:  <pre><code>venv/\n    bin/\n        activate\n    include/\n    lib/\n        python3.X/\n            site-packages/\n                package_name/\n    pyvenv.cfg\n</code></pre></p> <p>Looking at the natsort Python package, I am learning a bit about how these packages are typically structured. The package is installed in the <code>site-packages</code> folder, and the package's source code is in the <code>natsort</code> folder. The <code>natsort</code> folder contains the <code>__init__.py</code> file, which is the package's entry point for import. The <code>natsort</code> folder also contains the <code>__main__.py</code> file, which is the package's entry point when running the package as a script. Looking at my own package, the package structure is root/src/package_name, but when installed, the package structure is root/site-packages/package_name.</p> <p>Therefore, in the index.toml files, the relative file paths should be relative to the src/package_name folder, because that's the root folder when the package is installed. Therefore, the pyproject.toml may not actually need to have a path to the index.toml at all! I'll just assume that the index.toml is located in src/package_name.</p> <p>But then the question is, without the inclusion of the pyproject.toml file, how do I know what the dependencies are? I think I need to include the pyproject.toml file in the distributed package instead of making people list dependencies in a separate file.</p> <p>Maybe the better format is just for the index.toml file to contain the dependencies AND the paths to the configuration files? That way, the pyproject.toml file is not needed at all.</p> <p>So, the index.toml file should contain the following: <pre><code>dependencies = [] # Indicates that there are no dependencies\nbridges = [] # Indicates that there are no bridges\npaths = [\n    \"config_file1.toml\",\n    \"config_file2.toml\"\n]\n</code></pre></p> <p>It also appears that whether or not I include the following dictates whether the package's sdist includes the \"src\" folder. E.g. if the below is included in the pyproject.toml, and I have \"src/package_name/test.py\", then when the sdist is created, it'll be \"site-packages/package_name/test.py\". If the below is not included, then the sdist and project directory folders will exactly match. It seems that the contents of this line are reflected in the dist/package_name.version.tar.gz file, but not in the installed package. <pre><code>[tool.hatch.build]\ninclude = [\n    \"src/package_dag_compiler/**\"\n]\n</code></pre></p> <p>I am also learning a valuable lesson about the difference between <code>sdists</code> (compressed .py files) and <code>wheels</code> (compiled binaries of the package's code). From the Python Packaging User Guide:</p> <ol> <li> <p>Do I need both sdists and wheels? </p> <ul> <li>\"For pure-Python packages, the difference between sdists and wheels is less marked. There is normally one single wheel, for all platforms and Python versions. Python is an interpreted language, which does not need ahead-of-time compilation, so wheels contain .py files just like sdists.\"</li> </ul> </li> <li> <p>What's in a wheel?</p> <ul> <li>\"With that being said, there are still important differences between sdists and wheels, even for pure Python projects. Wheels are meant to contain exactly what is to be installed, and nothing more. In particular, wheels should never include tests and documentation, while sdists commonly do.\"</li> </ul> </li> <li> <p>Are wheels needed for pure Python projects?</p> <ul> <li>\"At a glance, you might wonder if wheels are really needed for \u201cplain and basic\u201d pure Python projects. Keep in mind that due to the flexibility of sdists, installers like pip cannot install from sdists directly \u2013 they need to first build a wheel, by invoking the build backend that the sdist specifies (the build backend may do all sorts of transformations while building the wheel, such as compiling C extensions). For this reason, even for a pure Python project, you should always upload both an sdist and a wheel to PyPI or other package indices. This makes installation much faster for your users, since a wheel is directly installable. By only including files that must be installed, wheels also make for smaller downloads.\"</li> </ul> </li> </ol>"},{"location":"dev_blog/2024-10-02/#editable-installs","title":"Editable installs","text":"<p>This detour has turned into a deep dive on Python packaging, which is helpful. I discovered that essentially, by default the /src/project_name folder is treated as the root folder when the package is built and when it is installed, with the exception that the sdist build has all files if not specified.</p> <p>The editable installs work by putting a direct_urls.json file in the site-packages/package_name folder. Sometimes it feels finicky, switching between editable and non-editable installs, but it seems to work.</p>"},{"location":"dev_blog/2024-10-03/","title":"October 3, 2024","text":"<p>Discovered how Hatch (Python's recommended build backend) determines which files to include: https://hatch.pypa.io/latest/plugins/builder/wheel/#default-file-selection. For my purposes, the relevant idea is that it'll include all files in the src//init.py folder, but the init.py file must be present. <p>These can be overriden using the [tool.hatch.build.targets.wheel] table.</p>"},{"location":"dev_blog/2024-10-05/","title":"October 5, 2024","text":"<p>Today I've been testing what I've written so far, which is reading in the files and constructing the DAG for one package. I am now trying to incorporate a second package, which led me a question about how to specify a local dependency in pyproject.toml.</p> <p>Here is the relevant documentation: https://peps.python.org/pep-0440/#direct-references and https://hatch.pypa.io/latest/config/metadata/#allowing-direct-references</p> <p>The syntax for adding a package from disk is: <pre><code>[tool.hatch.metadata]\nallow-direct-references = true\n\n[project]\ndependencies = [\n    \"package_name @ file:///path/to/folder/containing/dependency\"\n]\n</code></pre></p>"}]}